{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66ac76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import glob\n",
    "import json\n",
    "import copy\n",
    "import tqdm\n",
    "import time\n",
    "import base64\n",
    "from requests import post, get\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cabab0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client ID\n",
    "cid = ''\n",
    "\n",
    "# Client secret\n",
    "secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the file names scraped from rate your music\n",
    "rating = ['top','bottom','popular','esoteric','diverse']\n",
    "path = \"data/rate_your_music_data/{}/\"\n",
    "all_paths = {}\n",
    "for order in rating:\n",
    "    temp = path.format(order)\n",
    "    all_paths[order] = []\n",
    "    for file in glob.glob(temp+\"*.json\"):\n",
    "        all_paths[order].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the authorization token\n",
    "def get_token():\n",
    "    auth_string = cid + \":\" + secret\n",
    "    auth_bytes = auth_string.encode(\"utf-8\")\n",
    "    auth_base64 = str(base64.b64encode(auth_bytes),\"utf-8\")\n",
    "    \n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": \"Basic \" + auth_base64,\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\"grant_type\":\"client_credentials\"}\n",
    "    \n",
    "    result = post(url, headers = headers, data = data)\n",
    "    res = json.loads(result.content)\n",
    "    token = res[\"access_token\"]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the token\n",
    "token = get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the authentication headers\n",
    "def get_auth_header(token):\n",
    "    return {\"Authorization\":\"Bearer \"+ token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get uri's of album and artist\n",
    "def api_get_uri(album,artist):\n",
    "    url = \"https://api.spotify.com/v1/search?\"\n",
    "    headers = get_auth_header(token)\n",
    "    query = f\"q=album:{album} artist:{artist}&type=album&limit=1\"\n",
    "    result = get(url+query, headers = headers)\n",
    "    \n",
    "    # Returns -1 if rate limit of spotify is hit\n",
    "    if result.status_code == 429:\n",
    "        print(\"Limit Reached\")\n",
    "        return -1, -1\n",
    "    else:\n",
    "        result = json.loads(result.content)\n",
    "        if result['albums']['items']:\n",
    "            album_uri = result['albums']['items'][0]['uri']\n",
    "            artist_uri = result['albums']['items'][0]['artists'][0]['uri']\n",
    "            return album_uri, artist_uri\n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get artist data\n",
    "def api_get_artist_data(uri):\n",
    "    id_ = uri.split(\":\")[-1]\n",
    "    url = f\"https://api.spotify.com/v1/artists/{id_}\"\n",
    "    headers = get_auth_header(token)\n",
    "    result = get(url, headers = headers)\n",
    "    \n",
    "    if result.status_code == 429:\n",
    "        print(\"Limit Reached\")\n",
    "        return -1\n",
    "    else:\n",
    "        one = json.loads(result.content)\n",
    "        return one\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get track features\n",
    "def api_get_audio_feat(uri):\n",
    "    id_ = uri.split(\":\")[-1]\n",
    "    url = f\"https://api.spotify.com/v1/audio-features/{id_}\"\n",
    "    headers = get_auth_header(token)\n",
    "    \n",
    "    time.sleep(sleeper['feat'])\n",
    "    result = get(url, headers = headers)\n",
    "    if result.status_code == 429:\n",
    "        print(\"Limit Reached\")\n",
    "        sleeper['feat']+=0.5\n",
    "        return -1\n",
    "    else:\n",
    "        one = json.loads(result.content)\n",
    "        return one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get track data\n",
    "def api_get_track_data(uri):\n",
    "    id_ = uri.split(\":\")[-1]\n",
    "    \n",
    "    url = f\"https://api.spotify.com/v1/tracks/{id_}\"\n",
    "    headers = get_auth_header(token)\n",
    "    \n",
    "    time.sleep(sleeper['tracks'])\n",
    "    result = get(url, headers = headers)\n",
    "    \n",
    "    if result.status_code == 429:\n",
    "        print(\"Limit Reached\")\n",
    "        sleeper['tracks']+=0.5\n",
    "        return -1\n",
    "    else:\n",
    "        one = json.loads(result.content)\n",
    "        return one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get tracks of each album and its features\n",
    "def api_get_album_tracks(uri):\n",
    "    url = \"https://api.spotify.com/v1\"\n",
    "    \n",
    "    headers = get_auth_header(token)\n",
    "    id_ = uri.split(\":\")[-1]\n",
    "    query = \"/albums/{}/tracks?offset=0&limit=50\".format(id_)\n",
    "    result = get(url+query,headers = headers)\n",
    "    \n",
    "    if result.status_code == 429:\n",
    "        print(\"Limit Reached\")\n",
    "        return -1\n",
    "    else:\n",
    "        one = json.loads(result.content)\n",
    "        data = pd.DataFrame(one)\n",
    "        tracks = []\n",
    "        for i, x in data['items'].items():\n",
    "            track = {}\n",
    "            track['spotify track uri'] = x['uri']\n",
    "            track['spotify track name'] = x['name']\n",
    "            track['spotify track number'] = x['track_number']\n",
    "            track['spotify disc number'] = x['disc_number']\n",
    "            \n",
    "            \n",
    "            track_data = api_get_track_data(x['uri'])\n",
    "            if track_data == -1:\n",
    "                track['spotify track popularity'] = None\n",
    "                track['spotify track duration'] = None\n",
    "            else:\n",
    "                track['spotify track popularity'] = track_data['popularity']\n",
    "                track['spotify track duration'] = track_data['duration_ms']\n",
    "            \n",
    "            features = api_get_audio_feat(x['uri'])\n",
    "            if features != None and features != -1:\n",
    "                 track['spotify track features'] = {\n",
    "                'acousticness': features['acousticness'],\n",
    "                'danceability': features['danceability'],\n",
    "                'energy': features['energy'],\n",
    "                'instrumentalness': features['instrumentalness'],\n",
    "                'liveness': features['liveness'],\n",
    "                'loudness': features['loudness'],\n",
    "                'speechiness': features['speechiness'],\n",
    "                'tempo': features['tempo'],\n",
    "                'valence': features['valence']}\n",
    "            else:\n",
    "                track['spotify track features'] = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            tracks.append(track)\n",
    "        return tracks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                         | 67/1040 [16:35<4:44:36, 17.55s/it]"
     ]
    }
   ],
   "source": [
    "# Loading Data and adding tracks for each album\n",
    "# Counter to slow down the API calls\n",
    "sleeper = defaultdict(lambda: 0.5)\n",
    "# Path to store file names, album and artist if the data was not pulled\n",
    "t = int(time.time()*100)\n",
    "path_for_no_data = f\"data/spotify_song_data/no_data/no_data_{t}.json\"\n",
    "\n",
    "# Counter used to store data\n",
    "counter = 1\n",
    "\n",
    "# Storing the API calls that did not work\n",
    "not_work = []\n",
    "\n",
    "for order in all_paths.keys():\n",
    "    \n",
    "    # Search for a specific category\n",
    "    if order != 'top':\n",
    "        continue\n",
    "    \n",
    "    # Iterating through all the file paths in that category\n",
    "    for j_file in all_paths[order]:\n",
    "        \n",
    "        # Getting the year from the file path\n",
    "        year = j_file[-9:-5]\n",
    "        \n",
    "        # Look for a specific year\n",
    "        if int(year) not in [2018]:\n",
    "            continue\n",
    "        \n",
    "        # Opening a file \n",
    "        with open(j_file) as f:\n",
    "            data_dict = json.load(f)\n",
    "        \n",
    "        # Appending the new dictionaries with added information into new_vals\n",
    "        new_vals = []\n",
    "        \n",
    "        # Iterating through each entry in the original dictionary\n",
    "        for entry in tqdm.tqdm(data_dict):\n",
    "            \n",
    "            # Sleeper to reduce timeout\n",
    "            time.sleep(sleeper['search'])\n",
    "            \n",
    "            # Checking for errors other than the limit reached\n",
    "            try:\n",
    "                # Getting the URI's of the album and artist\n",
    "                entry[\"spotify album uri\"],entry[\"spotify artist uri\"] =  api_get_uri(entry['Album'],entry['Artist Name'])\n",
    "            except:\n",
    "                \n",
    "                # If the info is not retrieved save the file name, album name and artist name to a file\n",
    "                not_work.append({\"file\":j_file,\"album\":entry['Album'],\"artist\":entry['Artist Name']})\n",
    "                with open(path_for_no_data, 'w') as file:\n",
    "                    json.dump(not_work, file)\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            # Checking to see whether limit has reached (if limit has reached all functions return -1)\n",
    "            if entry[\"spotify album uri\"] == -1:\n",
    "                \n",
    "                # Increase the sleep time if limit has reached\n",
    "                sleeper['search']+=0.5\n",
    "                \n",
    "                # Appending the file name, album and artist since the data retrieval did not work\n",
    "                not_work.append({\"file\":j_file,\"album\":entry['Album'],\"artist\":entry['Artist Name']})\n",
    "                with open(path_for_no_data, 'w') as file:\n",
    "                    json.dump(not_work, file)\n",
    "                continue\n",
    "            \n",
    "            # To store artist data - we run through the same steps as for uri retrieval\n",
    "            artist_data = {}\n",
    "            if entry['spotify artist uri'] != None:\n",
    "                \n",
    "                time.sleep(sleeper['artist'])\n",
    "                \n",
    "                try:\n",
    "                    artist = api_get_artist_data(entry['spotify artist uri'])\n",
    "                    if artist == -1:\n",
    "                        sleeper['artist']+=0.5\n",
    "                    else:\n",
    "                        artist_data = {\n",
    "                        'spotify artist name': artist['name'],\n",
    "                        'spotify artist popularity': artist['popularity'],\n",
    "                        'spotify artist followers': artist['followers']['total'],\n",
    "                        'spotify artist genres': artist['genres']}\n",
    "                except:\n",
    "                    not_work.append({\"file\":j_file,\"album\":entry['Album'],\"artist\":entry['Artist Name']})\n",
    "                    with open(path_for_no_data, 'w') as file:\n",
    "                        json.dump(not_work, file)\n",
    "                \n",
    "\n",
    "            # To get album track data - we run through the same steps as for uri retrieval\n",
    "            if entry['spotify album uri'] != None:\n",
    "                \n",
    "                time.sleep(sleeper['album'])\n",
    "                try:\n",
    "                    # Getting the tracks, track data and features\n",
    "                    result = api_get_album_tracks(entry['spotify album uri'])\n",
    "\n",
    "                    if result == -1:\n",
    "                        sleeper['album']+=0.5\n",
    "                        not_work.append({\"file\":j_file,\"album\":entry['Album'],\"artist\":entry['Artist Name']})\n",
    "                        with open(path_for_no_data, 'w') as file:\n",
    "                            json.dump(not_work, file)\n",
    "                        continue\n",
    "                        \n",
    "                    # Checkin to see if the number of tracks returned is not 0\n",
    "                    if len(result)!=0:\n",
    "                        for res in result:\n",
    "                            # Creating a new dictionary with added information\n",
    "                            dup_entry = copy.deepcopy(entry)\n",
    "                            dup_entry.update(res)\n",
    "                            dup_entry.update(artist_data)\n",
    "                            \n",
    "                            # Appending to the main list\n",
    "                            new_vals.append(dup_entry) \n",
    "                    else:\n",
    "                        not_work.append({\"file\":j_file,\"album\":entry['Album'],\"artist\":entry['Artist Name']})\n",
    "                        with open(path_for_no_data, 'w') as file:\n",
    "                            json.dump(not_work, file)\n",
    "                except:\n",
    "                    not_work.append({\"file\":j_file,\"album\":entry['Album'],\"artist\":entry['Artist Name']})\n",
    "                    with open(path_for_no_data, 'w') as file:\n",
    "                        json.dump(not_work, file)\n",
    "                    \n",
    "                # For every 10 counts we save the data - to prevent losing all information in case of rate limit reached\n",
    "                if counter%10 == 0:\n",
    "                    store_path = \"data/spotify_song_data/{}/{}\".format(order,year+\".json\")\n",
    "                    with open(store_path, 'w') as file:\n",
    "                            json.dump(new_vals, file)\n",
    "                            \n",
    "                # Getting a new token every 40 iterations\n",
    "                if counter%40 == 0:\n",
    "                    token = get_token()\n",
    "                counter+=1\n",
    "            else:\n",
    "                not_work.append({\"file\":j_file,\"album\":entry['Album'],\"artist\":entry['Artist Name']})\n",
    "                with open(path_for_no_data, 'w') as file:\n",
    "                    json.dump(not_work, file)\n",
    "                    \n",
    "        # Store all the data into the year for the particular chart if all iterations are completed\n",
    "        store_path = \"data/spotify_song_data/{}/{}\".format(order,year+\".json\")            \n",
    "        with open(store_path, 'w') as file:\n",
    "            json.dump(new_vals, file)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
